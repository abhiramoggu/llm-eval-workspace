# llm-eval-workspace
This repository is created to maintain files for graduation research. The goal is to create an evaluation system for comparing the error correction across multi-turn conversations in conversational recommender systems (CRS) made of LLMs. Conversations are simulated with LLM-based users. These convos are scored with quantitative metrics and LLMs. 
